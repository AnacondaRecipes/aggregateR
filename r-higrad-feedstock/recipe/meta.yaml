{% set version = '0.1.0' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-higrad
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/higrad_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/higrad/higrad_{{ version }}.tar.gz
  sha256: 52c971fdf86a693c1e6994056f23b9f6493957655b1f3a94f16fd7ed31da2a61

build:
  merge_build_host: True  # [win]
  # If this is a new build for the same version, increment the build number.
  number: 0
  # no skip
  noarch: generic

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

requirements:
  build:
    - {{posix}}zip               # [win]

  host:
    - r-base
    - r-matrix

  run:
    - r-base
    - r-matrix

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('higrad')"           # [not win]
    - "\"%R%\" -e \"library('higrad')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://CRAN.R-project.org/package=higrad
  license: GPL-3
  summary: 'Implements the Hierarchical Incremental GRAdient Descent (HiGrad) algorithm, a first-order
    algorithm for finding the minimizer of a function in online learning just like stochastic
    gradient descent (SGD). In addition, this method attaches a confidence interval
    to assess the uncertainty of its predictions. See Su and Zhu (2018) <arXiv:1802.04876>
    for details. '

  license_family: GPL3
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/GPL-3'

extra:
  recipe-maintainers:
    - katietz

# The original CRAN metadata for this package was:

# Package: higrad
# Type: Package
# Title: Statistical Inference for Online Learning and Stochastic Approximation via HiGrad
# Version: 0.1.0
# Authors@R: c( person("Weijie", "Su", email = "suw@wharton.upenn.edu", role = "aut"), person("Yuancheng", "Zhu", email = "yuancheng.zhu@gmail.com", role = c("aut", "cre")))
# Description: Implements the Hierarchical Incremental GRAdient Descent (HiGrad) algorithm, a first-order algorithm for finding the minimizer of a function in online learning just like stochastic gradient descent (SGD). In addition, this method attaches a confidence interval to assess the uncertainty of its predictions. See Su and Zhu (2018) <arXiv:1802.04876> for details.
# License: GPL-3
# Encoding: UTF-8
# LazyData: true
# RoxygenNote: 6.0.1
# Imports: Matrix
# NeedsCompilation: no
# Packaged: 2018-03-14 13:29:18 UTC; Yuancheng
# Author: Weijie Su [aut], Yuancheng Zhu [aut, cre]
# Maintainer: Yuancheng Zhu <yuancheng.zhu@gmail.com>
# Repository: CRAN
# Date/Publication: 2018-03-14 15:44:13 UTC

# See
# https://docs.conda.io/projects/conda-build for
# more information about meta.yaml
