{% set version = '1.2.1' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-lexicon
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/lexicon_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/lexicon/lexicon_{{ version }}.tar.gz
  sha256: cc0023d16309fc24e0a3a1f01887b19d05f2eb3a7ee9102415595d0335d3f974

build:
  merge_build_host: True  # [win]
  # If this is a new build for the same version, increment the build number.
  number: 0
  # no skip
  noarch: generic

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

requirements:
  build:
    - {{ posix }}zip               # [win]

  host:
    - r-base
    - r-data.table
    - r-syuzhet >=1.0.1

  run:
    - r-base
    - r-data.table
    - r-syuzhet >=1.0.1

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('lexicon')"           # [not win]
    - "\"%R%\" -e \"library('lexicon')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://github.com/trinker/lexicon
  license: GPL-3
  summary: A collection of lexical hash tables, dictionaries, and word lists.
  license_family: GPL3
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/GPL-3'

# The original CRAN metadata for this package was:

# Package: lexicon
# Title: Lexicons for Text Analysis
# Version: 1.2.1
# Maintainer: Tyler Rinker <tyler.rinker@gmail.com>
# Description: A collection of lexical hash tables, dictionaries, and word lists.
# Depends: R (>= 3.2.2)
# Imports: data.table, syuzhet (>= 1.0.1)
# Authors@R: c( person("Tyler", "Rinker", email = "tyler.rinker@gmail.com", role = c("aut", "cre", "cph")), person("University of Notre Dame", role = c('dtc', "cph")), person("Department of Knowledge Technologies", role = c('dtc', "cph")), person("Unicode, Inc.", role = c('dtc', "cph")), person("John", "Higgins", role = c('dtc', "cph")), person("Grady", "Ward", role = c('dtc')), person("Heiko", "Possel", role = c('dtc')), person("Michal Boleslav", "Mechura", role = c('dtc', "cph")), person("Bing", "Liu", role = c('dtc')), person("Minqing", "Hu", role = c('dtc')), person("Saif M.", "Mohammad", role = c('dtc')), person("Peter", "Turney", role = c('dtc')), person("Erik", "Cambria", role = c('dtc')), person('Soujanya', 'Poria', role = c('dtc')), person('Rajiv', 'Bajpai', role = c('dtc')), person("Bjoern", "Schuller", role = c('dtc')), person("SentiWordNet", role = c('dtc', "cph")), person("Liang", "Wu", role = c('dtc', "cph")), person("Fred", "Morstatter", role = c('dtc', "cph")), person("Huan", "Liu", role = c('dtc', "cph")), person("Grammar Revolution", role = c('dtc', "cph")), person("Vidar", "Holen", role = c('dtc', "cph")), person("Alejandro U.", "Alvarez", role = c('dtc', "cph")), person("Stackoverflow User user2592414", role = c('dtc', "cph")), person("BannedWordList.com", role = c('dtc', "cph")), person("Apache Software Foundation", role = c('dtc', "cph")), person("Andrew Kachites", "McCallum", role = c('dtc', "cph")), person("Alireza", "Savand", role = c('dtc', "cph")), person("Zact", 'Anger', role = c('dtc', "cph")), person("Titus", "Wormer", role = c('dtc', "cph")), person("Colin", "Martindale", role = c('dtc', "cph")), person("John", "Wiseman", role = c('dtc', "cph")), person("Nadra", "Pencle", role = c('dtc', "cph")), person("Irina", "Malaescu", role = c('dtc', "cph")) )
# License: GPL-3
# LazyData: TRUE
# Encoding: UTF-8
# RoxygenNote: 6.1.1
# BugReports: https://github.com/trinker/lexicon/issues?state=open
# URL: https://github.com/trinker/lexicon
# Collate: 'available_data.R' 'cliches.R' 'common_names.R' 'constraining_loughran_mcdonald.R' 'freq_first_names.R' 'freq_last_names.R' 'function_words.R' 'grady_augmented.R' 'hash_emoticons.R' 'hash_grady_pos.R' 'hash_internet_slang.R' 'hash_lemmas.R' 'hash_nrc_emotion.R' 'hash_sentiment_emojis.R' 'hash_sentiment_huliu.R' 'utils.R' 'hash_sentiment_jockers.R' 'hash_sentiment_jockers_rinker.R' 'hash_sentiment_loughran_mcdonald.R' 'hash_sentiment_nrc.R' 'hash_sentiment_senticnet.R' 'hash_sentiment_sentiword.R' 'hash_sentiment_slangsd.R' 'hash_sentiment_socal_google.R' 'hash_valence_shifters.R' 'key_contractions.R' 'key_corporate_social_responsibility.R' 'key_grade.R' 'key_ratings.R' 'key_regressive_imagery.R' 'lexicon-package.R' 'modal_loughran_mcdonald.R' 'nrc_emotions.R' 'pos_action_verb.R' 'pos_df_irregular_nouns.R' 'pos_df_pronouns.R' 'pos_interjections.R' 'pos_preposition.R' 'profanity_alvarez.R' 'profanity_arr_bad.R' 'profanity_banned.R' 'profanity_racist.R' 'profanity_zac_anger.R' 'sw_dolch.R' 'sw_fry_100.R' 'sw_fry_1000.R' 'sw_fry_200.R' 'sw_fry_25.R' 'sw_jockers.R' 'sw_loughran_mcdonald.R' 'sw_lucene.R' 'sw_mallet.R' 'sw_python.R'
# NeedsCompilation: no
# Packaged: 2019-03-20 16:40:42 UTC; trinker
# Author: Tyler Rinker [aut, cre, cph], University of Notre Dame [dtc, cph], Department of Knowledge Technologies [dtc, cph], Unicode, Inc. [dtc, cph], John Higgins [dtc, cph], Grady Ward [dtc], Heiko Possel [dtc], Michal Boleslav Mechura [dtc, cph], Bing Liu [dtc], Minqing Hu [dtc], Saif M. Mohammad [dtc], Peter Turney [dtc], Erik Cambria [dtc], Soujanya Poria [dtc], Rajiv Bajpai [dtc], Bjoern Schuller [dtc], SentiWordNet [dtc, cph], Liang Wu [dtc, cph], Fred Morstatter [dtc, cph], Huan Liu [dtc, cph], Grammar Revolution [dtc, cph], Vidar Holen [dtc, cph], Alejandro U. Alvarez [dtc, cph], Stackoverflow User user2592414 [dtc, cph], BannedWordList.com [dtc, cph], Apache Software Foundation [dtc, cph], Andrew Kachites McCallum [dtc, cph], Alireza Savand [dtc, cph], Zact Anger [dtc, cph], Titus Wormer [dtc, cph], Colin Martindale [dtc, cph], John Wiseman [dtc, cph], Nadra Pencle [dtc, cph], Irina Malaescu [dtc, cph]
# Repository: CRAN
# Date/Publication: 2019-03-21 10:40:03 UTC

# See
# https://docs.conda.io/projects/conda-build for
# more information about meta.yaml
