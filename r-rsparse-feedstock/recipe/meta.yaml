{% set version = '0.5.1' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-rsparse
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/rsparse_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/rsparse/rsparse_{{ version }}.tar.gz
  sha256: 1fb2429a066bfd51d2618aa196b4111d7e768bf4920249366ddd402a2aa56d96

build:
  merge_build_host: True  # [win]
  # If this is a new build for the same version, increment the build number.
  number: 0
  # no skip

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

# Suggests: testthat, covr
requirements:
  build:
    - {{ compiler('c') }}              # [not win]
    - {{ compiler('m2w64_c') }}        # [win]
    - {{ compiler('cxx') }}            # [not win]
    - {{ compiler('m2w64_cxx') }}      # [win]
    - {{ posix }}filesystem        # [win]
    - {{ posix }}sed               # [win]
    - {{ posix }}grep              # [win]
    - {{ posix }}autoconf
    - {{ posix }}automake          # [not win]
    - {{ posix }}automake-wrapper  # [win]
    - {{ posix }}pkg-config
    - {{ posix }}make
    - {{ posix }}coreutils         # [win]
    - {{ posix }}zip               # [win]

  host:
    - r-base
    - r-matrix >=1.3
    - r-matrixextra >=0.1.7
    - r-rcpp >=0.11
    - r-rcpparmadillo >=0.9.100.5.0
    - r-rhpcblasctl
    - r-data.table >=1.10.0
    - r-float >=0.2_2
    - r-lgr >=0.2

  run:
    - r-base
    - {{native}}gcc-libs         # [win]
    - r-matrix >=1.3
    - r-matrixextra >=0.1.7
    - r-rcpp >=0.11
    - r-rcpparmadillo >=0.9.100.5.0
    - r-rhpcblasctl
    - r-data.table >=1.10.0
    - r-float >=0.2_2
    - r-lgr >=0.2

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('rsparse')"           # [not win]
    - "\"%R%\" -e \"library('rsparse')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://github.com/rexyai/rsparse
  license: GPL-2
  summary: 'Implements many algorithms for statistical learning on sparse matrices - matrix factorizations,
    matrix completion, elastic net regressions, factorization machines. Also ''rsparse''
    enhances ''Matrix'' package by providing methods for multithreaded <sparse, dense>
    matrix products and native slicing of the sparse matrices in Compressed Sparse Row
    (CSR) format. List of the algorithms for regression problems: 1) Elastic Net regression
    via Follow The Proximally-Regularized Leader (FTRL) Stochastic Gradient Descent
    (SGD), as per McMahan et al(, <doi:10.1145/2487575.2488200>) 2) Factorization Machines
    via SGD, as per Rendle (2010, <doi:10.1109/ICDM.2010.127>) List of algorithms for
    matrix factorization and matrix completion: 1) Weighted Regularized Matrix Factorization
    (WRMF) via Alternating Least Squares (ALS) - paper by Hu, Koren, Volinsky (2008,
    <doi:10.1109/ICDM.2008.22>) 2) Maximum-Margin Matrix Factorization via ALS, paper
    by Rennie, Srebro (2005, <doi:10.1145/1102351.1102441>) 3) Fast Truncated Singular
    Value Decomposition (SVD), Soft-Thresholded SVD, Soft-Impute matrix completion via
    ALS - paper by Hastie, Mazumder et al. (2014, <arXiv:1410.2596>) 4) Linear-Flow
    matrix factorization, from ''Practical linear models for large-scale one-class collaborative
    filtering'' by Sedhain, Bui, Kawale et al (2016, ISBN:978-1-57735-770-4) 5) GlobalVectors
    (GloVe) matrix factorization via SGD, paper by Pennington, Socher, Manning (2014,
    <https://aclanthology.org/D14-1162/>) Package is reasonably fast and memory efficient
    - it allows to work with large datasets - millions of rows and millions of columns.
    This is particularly useful for practitioners working on recommender systems.'
  license_family: GPL2
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/GPL-2'

# The original CRAN metadata for this package was:

# Package: rsparse
# Type: Package
# Title: Statistical Learning on Sparse Matrices
# Version: 0.5.1
# Authors@R: c( person("Dmitriy", "Selivanov", role=c("aut", "cre", "cph"), email="ds@rexy.ai", comment = c(ORCID = "0000-0001-5413-1506")), person("David", "Cortes", role="ctb"), person("Drew", "Schmidt", role="ctb", comment="configure script for BLAS, LAPACK detection"), person("Wei-Chen", "Chen", role="ctb", comment="configure script and work on linking to float package") )
# Maintainer: Dmitriy Selivanov <ds@rexy.ai>
# Description: Implements many algorithms for statistical learning on sparse matrices - matrix factorizations, matrix completion, elastic net regressions, factorization machines. Also 'rsparse' enhances 'Matrix' package by providing methods for multithreaded <sparse, dense> matrix products and native slicing of the sparse matrices in Compressed Sparse Row (CSR) format. List of the algorithms for regression problems: 1) Elastic Net regression via Follow The Proximally-Regularized Leader (FTRL) Stochastic Gradient Descent (SGD), as per McMahan et al(, <doi:10.1145/2487575.2488200>) 2) Factorization Machines via SGD, as per Rendle (2010, <doi:10.1109/ICDM.2010.127>) List of algorithms for matrix factorization and matrix completion: 1) Weighted Regularized Matrix Factorization (WRMF) via Alternating Least Squares (ALS) - paper by Hu, Koren, Volinsky (2008, <doi:10.1109/ICDM.2008.22>) 2) Maximum-Margin Matrix Factorization via ALS, paper by Rennie, Srebro (2005, <doi:10.1145/1102351.1102441>) 3) Fast Truncated Singular Value Decomposition (SVD), Soft-Thresholded SVD, Soft-Impute matrix completion via ALS - paper by Hastie, Mazumder et al. (2014, <arXiv:1410.2596>) 4) Linear-Flow matrix factorization, from 'Practical linear models for large-scale one-class collaborative filtering' by Sedhain, Bui, Kawale et al (2016, ISBN:978-1-57735-770-4) 5) GlobalVectors (GloVe) matrix factorization via SGD, paper by Pennington, Socher, Manning (2014, <https://aclanthology.org/D14-1162/>) Package is reasonably fast and memory efficient - it allows to work with large datasets - millions of rows and millions of columns. This is particularly useful for practitioners working on recommender systems.
# License: GPL (>= 2)
# Encoding: UTF-8
# LazyData: true
# ByteCompile: true
# Depends: R (>= 3.6.0), methods, Matrix (>= 1.3)
# Imports: MatrixExtra (>= 0.1.7), Rcpp (>= 0.11), data.table (>= 1.10.0), float (>= 0.2-2), RhpcBLASctl, lgr (>= 0.2)
# LinkingTo: Rcpp, RcppArmadillo (>= 0.9.100.5.0)
# Suggests: testthat, covr
# StagedInstall: TRUE
# URL: https://github.com/rexyai/rsparse
# BugReports: https://github.com/rexyai/rsparse/issues
# RoxygenNote: 7.2.1
# NeedsCompilation: yes
# Packaged: 2022-09-11 03:05:04 UTC; dselivanov
# Author: Dmitriy Selivanov [aut, cre, cph] (<https://orcid.org/0000-0001-5413-1506>), David Cortes [ctb], Drew Schmidt [ctb] (configure script for BLAS, LAPACK detection), Wei-Chen Chen [ctb] (configure script and work on linking to float package)
# Repository: CRAN
# Date/Publication: 2022-09-11 22:20:02 UTC

# See
# https://docs.conda.io/projects/conda-build for
# more information about meta.yaml
