{% set version = '5.0' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-adabag
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/adabag_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/adabag/adabag_{{ version }}.tar.gz
  sha256: ec58756fda2e64753d21e28d9e27ed34f28020045b199a58dcea06a3e2c3d60e

build:
  merge_build_host: True  # [win]
  # If this is a new build for the same version, increment the build number.
  number: 0
  # no skip
  noarch: generic

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

# Suggests: mlbench
requirements:
  build:
    - {{ posix }}zip               # [win]

  host:
    - r-base
    - r-consrank >=2.1.3
    - r-caret
    - r-doparallel
    - r-dplyr
    - r-foreach
    - r-rpart
    - r-tidyr

  run:
    - r-base
    - r-consrank >=2.1.3
    - r-caret
    - r-doparallel
    - r-dplyr
    - r-foreach
    - r-rpart
    - r-tidyr

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('adabag')"           # [not win]
    - "\"%R%\" -e \"library('adabag')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://CRAN.R-project.org/package=adabag
  license: GPL-2
  summary: It implements Freund and Schapire's Adaboost.M1 algorithm and Breiman's Bagging algorithm
    using classification trees as individual classifiers. Once these classifiers have
    been trained, they can be used to predict on new data. Also, cross validation estimation
    of the error can be done. Since version 2.0 the function margins() is available
    to calculate the margins for these classifiers. Also a higher flexibility is achieved
    giving access to the rpart.control() argument of 'rpart'. Four important new features
    were introduced on version 3.0, AdaBoost-SAMME (Zhu et al., 2009) is implemented
    and a new function errorevol() shows the error of the ensembles as a function of
    the number of iterations. In addition, the ensembles can be pruned using the option
    'newmfinal' in the predict.bagging() and predict.boosting() functions and the posterior
    probability of each class for observations can be obtained. Version 3.1 modifies
    the relative importance measure to take into account the gain of the Gini index
    given by a variable in each tree and the weights of these trees. Version 4.0 includes
    the margin-based ordered aggregation for Bagging pruning (Guo and Boukir, 2013)
    and a function to auto prune the 'rpart' tree. Moreover, three new plots are also
    available importanceplot(), plot.errorevol() and plot.margins(). Version 4.1 allows
    to predict on unlabeled data. Version 4.2 includes the parallel computation option
    for some of the functions. Version 5.0 includes the Boosting and Bagging algorithms
    for label ranking (Albano, Sciandra and Plaia, 2023).
  license_family: GPL2
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/GPL-2'

# The original CRAN metadata for this package was:

# Package: adabag
# Type: Package
# Title: Applies Multiclass AdaBoost.M1, SAMME and Bagging
# Version: 5.0
# Date: 2023-05-30
# Author: Alfaro, Esteban; Gamez, Matias and Garcia, Noelia; with contributions from L. Guo, A. Albano, M. Sciandra and A. Plaia
# Maintainer: Esteban Alfaro <Esteban.Alfaro@uclm.es>
# Depends: rpart, caret, foreach, doParallel, R (>= 4.0.0)
# Imports: methods, tidyr, dplyr, ConsRank (>= 2.1.3)
# Suggests: mlbench
# Description: It implements Freund and Schapire's Adaboost.M1 algorithm and Breiman's Bagging algorithm using classification trees as individual classifiers. Once these classifiers have been trained, they can be used to predict on new data. Also, cross validation estimation of the error can be done. Since version 2.0 the function margins() is available to calculate the margins for these classifiers. Also a higher flexibility is achieved giving access to the rpart.control() argument of 'rpart'. Four important new features were introduced on version 3.0, AdaBoost-SAMME (Zhu et al., 2009) is implemented and a new function errorevol() shows the error of the ensembles as a function of the number of iterations. In addition, the ensembles can be pruned using the option 'newmfinal' in the predict.bagging() and predict.boosting() functions and the posterior probability of each class for observations can be obtained. Version 3.1 modifies the relative importance measure to take into account the gain of the Gini index given by a variable in each tree and the weights of these trees. Version 4.0 includes the margin-based ordered aggregation for Bagging pruning (Guo and Boukir, 2013) and a function to auto prune the 'rpart' tree. Moreover, three new plots are also available importanceplot(), plot.errorevol() and plot.margins(). Version 4.1 allows to predict on unlabeled data. Version 4.2 includes the parallel computation option for some of the functions. Version 5.0 includes the Boosting and Bagging algorithms for label ranking (Albano, Sciandra and Plaia, 2023).
# License: GPL (>= 2)
# Encoding: UTF-8
# LazyLoad: yes
# LazyData: true
# NeedsCompilation: no
# Packaged: 2023-05-30 10:47:01 UTC; Esteban.Alfaro
# Repository: CRAN
# Date/Publication: 2023-05-31 17:00:07 UTC

# See
# https://docs.conda.io/projects/conda-build for
# more information about meta.yaml
