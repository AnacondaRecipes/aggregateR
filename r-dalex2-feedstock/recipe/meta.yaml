{% set version = '0.9' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-dalex2
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/DALEX2_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/DALEX2/DALEX2_{{ version }}.tar.gz
  sha256: 894a8796cdeea81742e111a4f22633a3365c87b2ff9f6e815999453db97e69cc

build:
  merge_build_host: True  # [win]
  # If this is a new build for the same version, increment the build number.
  number: 0
  # no skip
  noarch: generic

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

# Suggests: knitr, randomForest, tibble, testthat
requirements:
  build:
    - {{posix}}zip               # [win]

  host:
    - r-base

  run:
    - r-base

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('DALEX2')"           # [not win]
    - "\"%R%\" -e \"library('DALEX2')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: https://ModelOriented.github.io/DALEX2/
  license: GPL-3
  summary: Machine Learning models are widely used and have various applications in classification
    or regression tasks.  Due to increasing computational power, availability of new
    data sources and new methods, ML models are more and more complex.  Models created
    with techniques like boosting, bagging of neural networks are true black boxes.  It
    is hard to trace the link between input variables and model outcomes.  They are
    used because of high performance, but lack of interpretability is one of their weakest
    sides. In many applications we need to know, understand or prove how input variables
    are used in the model and what impact do they have on final model prediction.  DALEX2
    is a collection of tools that help to understand how complex predictive models are
    working. DALEX2 is a part of DrWhy universe for tools for Explanation, Exploration
    and Visualisation for Predictive Models.
  license_family: GPL3
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/GPL-3'

extra:
  recipe-maintainers:
    - katietz

# The original CRAN metadata for this package was:

# Package: DALEX2
# Title: Descriptive mAchine Learning EXplanations
# Version: 0.9
# Authors@R: person("Przemyslaw", "Biecek", email = "przemyslaw.biecek@gmail.com", role = c("aut", "cre"))
# Description: Machine Learning models are widely used and have various applications in classification or regression tasks.  Due to increasing computational power, availability of new data sources and new methods, ML models are more and more complex.  Models created with techniques like boosting, bagging of neural networks are true black boxes.  It is hard to trace the link between input variables and model outcomes.  They are used because of high performance, but lack of interpretability is one of their weakest sides. In many applications we need to know, understand or prove how input variables are used in the model and what impact do they have on final model prediction.  DALEX2 is a collection of tools that help to understand how complex predictive models are working. DALEX2 is a part of DrWhy universe for tools for Explanation, Exploration and Visualisation for Predictive Models.
# Depends: R (>= 3.1)
# License: GPL
# Encoding: UTF-8
# LazyData: true
# RoxygenNote: 6.1.1
# Suggests: knitr, randomForest, tibble, testthat
# URL: https://ModelOriented.github.io/DALEX2/
# BugReports: https://github.com/ModelOriented/DALEX2/issues
# NeedsCompilation: no
# Packaged: 2018-12-14 20:17:58 UTC; pbiecek
# Author: Przemyslaw Biecek [aut, cre]
# Maintainer: Przemyslaw Biecek <przemyslaw.biecek@gmail.com>
# Repository: CRAN
# Date/Publication: 2018-12-23 16:20:14 UTC

# See
# https://docs.conda.io/projects/conda-build for
# more information about meta.yaml
