{% set version = '0.2.1' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-reinforcelearn
  version: {{ version|replace("-", "_") }}

source:
  url:
    - {{ cran_mirror }}/src/contrib/reinforcelearn_{{ version }}.tar.gz
    - {{ cran_mirror }}/src/contrib/Archive/reinforcelearn/reinforcelearn_{{ version }}.tar.gz
  sha256: 6bec9ddb9edb936a62c95ab71ec50f70d02f6cef29408d541291889b0c16df9c

build:
  merge_build_host: True  # [win]
  # If this is a new build for the same version, increment the build number.
  number: 0
  # no skip
  noarch: generic

  # This is required to make R link correctly on Linux.
  rpaths:
    - lib/R/lib/
    - lib/

# Suggests: reticulate, keras, knitr, rmarkdown, testthat, covr, lintr
requirements:
  build:
    - {{posix}}zip               # [win]

  host:
    - r-base
    - r-r6 >=2.2.2
    - r-checkmate >=1.8.4
    - r-nnet >=7.3_12
    - r-purrr >=0.2.4

  run:
    - r-base
    - r-r6 >=2.2.2
    - r-checkmate >=1.8.4
    - r-nnet >=7.3_12
    - r-purrr >=0.2.4

test:
  commands:
    # You can put additional test commands to be run here.
    - $R -e "library('reinforcelearn')"           # [not win]
    - "\"%R%\" -e \"library('reinforcelearn')\""  # [win]

  # You can also put a file called run_test.py, run_test.sh, or run_test.bat
  # in the recipe that will be run at test time.

  # requires:
    # Put any additional test requirements here.

about:
  home: http://markusdumke.github.io/reinforcelearn
  license: MIT
  summary: Implements reinforcement learning environments and algorithms as described in Sutton
    & Barto (1998, ISBN:0262193981). The Q-Learning algorithm can be used with function
    approximation,  eligibility traces (Singh & Sutton (1996) <doi:10.1007/BF00114726>)  and
    experience replay (Mnih et al. (2013) <arXiv:1312.5602>).
  license_family: MIT
  license_file:
    - '{{ environ["PREFIX"] }}/lib/R/share/licenses/MIT'
    - LICENSE

extra:
  recipe-maintainers:
    - katietz

# The original CRAN metadata for this package was:

# Package: reinforcelearn
# Type: Package
# Title: Reinforcement Learning
# Version: 0.2.1
# Authors@R: person("Markus", "Dumke", email = {"markusdumke@gmail.com"}, role = c("aut", "cre"))
# Description: Implements reinforcement learning environments and algorithms as described in Sutton & Barto (1998, ISBN:0262193981). The Q-Learning algorithm can be used with function approximation,  eligibility traces (Singh & Sutton (1996) <doi:10.1007/BF00114726>)  and experience replay (Mnih et al. (2013) <arXiv:1312.5602>).
# License: MIT + file LICENSE
# Encoding: UTF-8
# LazyData: true
# Depends: R (>= 3.0.0)
# RoxygenNote: 6.1.1
# BugReports: https://github.com/markusdumke/reinforcelearn/issues
# URL: http://markusdumke.github.io/reinforcelearn
# SystemRequirements: (Python and gym only required if gym environments are used)
# Imports: checkmate (>= 1.8.4), R6 (>= 2.2.2), nnet (>= 7.3-12), purrr (>= 0.2.4)
# Suggests: reticulate, keras, knitr, rmarkdown, testthat, covr, lintr
# VignetteBuilder: knitr
# NeedsCompilation: no
# Packaged: 2019-04-08 19:08:56 UTC; Markus
# Author: Markus Dumke [aut, cre]
# Maintainer: Markus Dumke <markusdumke@gmail.com>
# Repository: CRAN
# Date/Publication: 2019-04-09 11:50:08 UTC

# See
# https://docs.conda.io/projects/conda-build for
# more information about meta.yaml
